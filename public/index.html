<!DOCTYPE html>
<html>
	<head>

	<link rel="stylesheet" type="text/css" href="stylesheets/style.css">
	</head>
	<body>
		<h1>AR Project</h1>
		<h4>Construction Zone!!!!!!</h4>

		<!--  Code taken from http://davidwalsh.name/browser-camera
		Ideally these elements aren't created until it's confirmed that the 
		client supports video/camera, but for the sake of illustrating the 
		elements involved, they are created with markup (not JavaScript)
		-->
		<video id="video" width="640" height="480" autoplay></video>
		<button id="snap">Snap Photo</button>
		<canvas id="canvas" width="640" height="480" style="border:1px solid #000000;"></canvas>



	</body>
	<script>



	/* Image process idea.  
		per image - define minimum size ( 100x100 in field of 1000x1000) <- performance idea
		per image if pixel color matches designated color within a range, 
			begin searching surrounding pixels, 
				Stage 1 : only store left most, right most, top most, bottom most 
					This gets a box to work with
				Stage 2 : identify local minimums and maximums within range of +/- a few pixels 
					This should get us points to draw a line and identify an aspect for image rendering and aid in shape recognition
	*/






		// Code taken from http://davidwalsh.name/browser-camera
		// Put event listeners into place
		window.addEventListener("DOMContentLoaded", function() {
			// Grab elements, create settings, etc.
			canvas = document.getElementById("canvas");
			context = canvas.getContext("2d");
			video = document.getElementById("video");

			// My code - overlay the canvas on top of the video.
			canvas.setAttribute("style", "left:" + video.offsetLeft + "px");
			canvas.setAttribute("style", "top:" + - video.offsetTop + "px");

			//videoObj are the constraints of the video stream
			videoObj = { "video": true , "audio" :false};
			errBack = function(error) {
				console.log("Video capture error: ", error.code); 
			};
			var ONCE = false;
			// Put video listeners into place
			if(navigator.getUserMedia) { // Standard
				navigator.getUserMedia(videoObj, function(stream) {
					if (!ONCE){
						console.log("got to STAGE 1 - vanilla flavor");
						console.log(stream);
						ONCE=true;
					}
					video.src = stream;
					video.play();
				}, errBack);
			} else if(navigator.webkitGetUserMedia) { 
				// WebKit-prefixed
				console.log("got to STAGE 2 - WebKit-prefixed");
				navigator.webkitGetUserMedia(videoObj, function(stream){
					video.src = window.webkitURL.createObjectURL(stream);
					video.play();
				}, errBack);
			}
			else if(navigator.mozGetUserMedia) { 
				// Firefox-prefixed
				console.log("got to STAGE 3 - Firefox-prefixed");
				navigator.mozGetUserMedia(videoObj, function(stream){
					video.src = window.URL.createObjectURL(stream);
					video.play();
				}, errBack);
			}
		}, false);

		// Located from MDN WebRTC_API Taking Still Photos
		function takePicture() {
	    var context = canvas.getContext('2d');
	   
	      context.drawImage(video, 0, 0);


	      //get the image data using canvas.getContext('2d').getImageData(starting x, starting y, width from x, height from y);
	      // the resultant data is a one dimensional array, every 4 elements are on pixel with the RGBA order ranged 0-255 (red green blue opacity)
	    	var data = context.getImageData(0,0, canvas.width, canvas.height);
	    	console.dir(data);


	    	//clear the canvas after we have our data
	    	context.clearRect ( 0 , 0 , canvas.width, canvas.height );
	    
	    console.log("takePicture worked!!!!")
	  }
		document.getElementById("snap").addEventListener('click', function (){takePicture()
		});

		function processImage (searchSignature, overlay){
			// searchSignature is an object containing minWidth, minHeight, maxHeight, maxWidth, minRed, maxRed, minBlue, maxBlue, minGreen, maxGreen - all opacity will be assumed @255, so no setting provided
			//optional --> lines equations to identify points/ratios of object proportions

			//overlay will be an object containing whatever we want to overlay with meta-data for desired size based on % of found object 

			// if machine learning can be found to be reasonable with time (local calculation likely)

			//search idea, break picture into grid. Search 1/10000px or 1/2500 px for appropriate color, then surrounding px color to get shape.  store leftmost, right most, topmost ,bottomost to get box.  also store local height max +/- a few pixels.  also store local minimums +/- pixels.  attempt to plot a line to identify a general shape and compare top/bottom ratios with provided ratios.   start with 640x480 and see how that goes. 
			//another idea with M Macatano, create color count for blocks of size 100x100 or so.
		}
		function xyTranslate (inputIndex, picData){
			//this function will take any one input from the data and return and object with x, y, r, g, b, a keys & appropriate values.  First values start at 0.
			result = {};
			// var canvas ={};
			// var canvas.width = 640;
			// keep referneces to calc number so there aren't multiple calculations for the same stuff.
			var numAll = inputIndex / canvas.width;
			var yCalc = Math.floor(numAll);
			var numX = ((numAll - yCalc) * canvas.width);
			var xCalc = Math.floor( numX / 4 );
			
			//get y - divide by canvas.width to get row
			result.y = yCalc;
			//get x - divide by 4 to get which x pixel.  left of the decimal is which pixel.  
			result.x = xCalc;

			if (picData){
			//right of the decimal is which RGB or A , R=.00, G=.25, B=.5, A=.75
			// get start index the do the count up from there.
			var startInd = Math.floor( inputIndex / 4 ) * 4; 
				result.r = picData[startInd];
				result.g = picData[startInd + 1];
				result.b = picData[startInd + 2];
				result.a = picData[startInd + 3];
			}
			return result;
		}


	</script>
</html>