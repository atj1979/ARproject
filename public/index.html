<!DOCTYPE html>
<html>
	<head>

	<link rel="stylesheet" type="text/css" href="stylesheets/style.css">
	<script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js"></script>
	</head>
	<body>
		<h1>AR Project</h1>
		<h4>Construction Zone!!!!!!</h4>

		<!--  Code taken from http://davidwalsh.name/browser-camera
		Ideally these elements aren't created until it's confirmed that the 
		client supports video/camera, but for the sake of illustrating the 
		elements involved, they are created with markup (not JavaScript)
		-->
		<video id="video" width="640" height="480" autoplay></video>
		<button id="snap">Snap Photo</button>
		<!--<div id="resultColor"> 
			<div>RED<input id="red" type="number"  /></div>
			<div>GREEN<input id="green" type="number" /></div>
			<div>BLUE<input id="blue" type="number" /></div>
		</div> -->
		<input id="range" type="number" value="100"></input>
		<input id="aim" type="checkbox">AIM </input>
		<button id="profile">Get Color Profile</button>
		<form id="color">
			<input id="background-color" 
				type="color" 
				value="#ff0000" 
				onchange="">
		</form>
		<canvas id="canvas" width="640" height="480" style="border:1px solid #000000;"></canvas>
		<div style="display:none;">
		  <img id="source" src="./images/shriner.jpeg" width="300" height="227" />
		</div>


	</body>
	<script>



	/* Image process idea.  
		per image - define minimum size ( 100x100 in field of 1000x1000) <- performance idea
		per image if pixel color matches designated color within a range, 
			begin searching surrounding pixels, 
				Stage 1 : only store left most, right most, top most, bottom most 
					This gets a box to work with
				Stage 2 : identify local minimums and maximums within range of +/- a few pixels 
					This should get us points to draw a line and identify an aspect for image rendering and aid in shape recognition
	*/






		// Code taken from http://davidwalsh.name/browser-camera
		// Put event listeners into place
		window.addEventListener("DOMContentLoaded", function() {
			// Grab elements, create settings, etc.
			var canvas = document.getElementById("canvas");
			var context = canvas.getContext("2d");
			var video = document.getElementById("video");

			// My code - overlay the canvas on top of the video.
			// canvas.setAttribute("style", "left:" + video.offsetLeft + "px");
			// canvas.setAttribute("style", "top:" + - video.offsetTop + "px");

			//videoObj are the constraints of the video stream
			var videoObj = { "video": true , "audio" :false};
			var errBack = function (error) {
				console.log("Video capture error: ", error.code); 
			};
			var ONCE = false;
			// Put video listeners into place
			if(navigator.getUserMedia) { // Standard
				navigator.getUserMedia(videoObj, function(stream) {
					if (!ONCE){
						console.log("got to STAGE 1 - vanilla flavor");
						console.log(stream);
						ONCE=true;
					}
					video.src = stream;
					video.play();
				}, errBack);
			} else if(navigator.webkitGetUserMedia) { 
				// WebKit-prefixed
				console.log("got to STAGE 2 - WebKit-prefixed");
				navigator.webkitGetUserMedia(videoObj, function(stream){
					video.src = window.webkitURL.createObjectURL(stream);
					video.play();
				}, errBack);
			}
			else if(navigator.mozGetUserMedia) { 
				// Firefox-prefixed
				console.log("got to STAGE 3 - Firefox-prefixed");
				navigator.mozGetUserMedia(videoObj, function(stream){
					video.src = window.URL.createObjectURL(stream);
					video.play();
				}, errBack);
			}
		}, false);

		// Located from MDN WebRTC_API Taking Still Photos
		function takePicture (colorObj) {
			// colorObj ? colorObj : {r:255, g:255, b:255};
	    var context = canvas.getContext('2d');
	   	var img = document.getElementById('source');
	      //I think we have to draw the image in order to get the data from it.
	      context.drawImage(video, 0, 0);

	      // get the image data using canvas.getContext('2d').getImageData(starting x, starting y, width from x, height from y);
	      // the resultant data is a one dimensional array, every 4 elements are on pixel with the RGBA order ranged 0-255 (red green blue opacity)
	    	var data = context.getImageData(0,0, canvas.width, canvas.height);
	    	console.log(colorObj);
	    	// clear the canvas after we have our data
	    	context.clearRect ( 0 , 0 , canvas.width, canvas.height );
	    	processImage(context, data, null, canvas.width, img, colorObj);
	  };

	  // function takeProfile(){
	  // 	var context = canvas.getContext('2d');
	  // 	var data = context.getImageData(0,0, canvas.width, canvas.height);
	  // 	//calculate input box of 20 by 20 centered top bottom left right

	  // 	context.drawImage(video, canvas.width-10, canvas.height-10, 20, 20);
	  // };

	  // document.getElementById("profile").addEventListener('click', function (){
	  // 	//
	  // 	takeProfile()
	  // });

		// function drawAim (){};

		// Add listener to radio aim button to get a color profile.
	  // document.getElementById("aim").addEventListener('',function (){});

		document.getElementById("snap").addEventListener('click', function (){
			var colorObj=hexToRGB(document.getElementById("background-color").value)
			// document.getElementById('red').value=colorObj.r;
			// document.getElementById('green').value=colorObj.g;
			// document.getElementById('blue').value=colorObj.b;
			takePicture(colorObj);
			var runTime = takePicture.bind(null, colorObj);
			var PID = setInterval(runTime, 100);
			 console.log(PID);
		});
		// getColorProfile will take a 20px by 20px box that will get a color profile of the image inside that box
		function getColorProfile(context, imgData, canvasWidth, colorObj){

			//calculate color by phasors - each phasor is 120 degrees apart.  (idea) take the absolute value of each vector the vectoral sum of all three phasors if white will be exactly in the center.  Near the edges will be 

		};


		function processImage (context, imgData, searchSignature, canvasWidth, overlay, colorObj){
			var start = new Date;
			// searchSignature is an object containing minWidth, minHeight, maxHeight, maxWidth, minRed, maxRed, minBlue, maxBlue, minGreen, maxGreen - all opacity will be assumed @255, so no setting provided
			//optional --> lines equations to identify points/ratios of object proportions


			//overlay will be an object containing whatever we want to overlay with meta-data for desired size based on % of found object 

			// if machine learning can be found to be reasonable with time (local calculation likely)

			//search idea, break picture into grid. Search 1/10000px or 1/2500 px for appropriate color, then surrounding px color to get shape.  store leftmost, right most, topmost ,bottomost to get box.  also store local height max +/- a few pixels.  also store local minimums +/- pixels.  attempt to plot a line to identify a general shape and compare top/bottom ratios with provided ratios.   start with 640x480 and see how that goes. 
			//another idea with M Macatano, create color count for blocks of size 100x100 or so.
			//Basic Search - search every pixel.
			//make new array to store results
			var resolution = 8;
			var pos;
			var average = {
				x:0,
				y:0,
				counter:0
			};
			var colorData ={
				min:{
					product:0,
					r:0,
					g:0,
					b:0
				},
				max:{
					product:0,
					r:0,
					g:0,
					b:0
				}
			};

			// guessed mcdonalds colors >150, >150, <120 RGB
			// better color identification could be identified by 3 phase - vector analysis
			// context.fillStyle = "yellow";
			
			for (var i = 0; i < imgData.data.length; i+=resolution){
				if (
					colorFilter(imgData, i, colorObj)
					&& noiseReduce(imgData, i, canvasWidth, colorObj)
				){
					pos = xyTranslate(i, canvasWidth);
					average.counter+=1;
					average.x+=pos.x;
					average.y+=pos.y;
					context.fillRect(pos.x, pos.y, 3, 3);
				}
			}
			average.x=average.x/average.counter;
			average.y=average.y/average.counter;
			context.fillStyle = "black";

			//context.drawImage(overlay,average.x, average.y, 423, 119);
			//context.fillRect(average.x, average.y, resolution, resolution);

			var stop = new Date;
			console.log("Calc time each frame",stop-start);
		};

		function colorCount (colorObj){
			//will get a count of pixels within a color range.
			//colorObj will contain min and max values for each RGB. 
		};

		function hexToRGB (hexVal){
			function hexToR(h) {return parseInt((cutHex(h)).substring(0,2),16)}
			function hexToG(h) {return parseInt((cutHex(h)).substring(2,4),16)}
			function hexToB(h) {return parseInt((cutHex(h)).substring(4,6),16)}
			function cutHex(h) {return (h.charAt(0)=="#") ? h.substring(1,7):h}
			var colorObj ={};
			colorObj.r = hexToR(hexVal);
			colorObj.g = hexToG(hexVal);
			colorObj.b = hexToB(hexVal);
			return colorObj;
		};

		function colorRange(centerColor, compColor, range){
			//distance = sqrt((r1-r2)^2+(g1-g2)^2+(b1-b2)^2)
			//the formula will be changed such that distance/range will be squared to prevent using Math.sqrt() because it is an expensive operation. Also Math.pow() will not be used because it is also slightly more expensive, because the function call is slightly more expensive. 
			// console.log(compColor);
			
			if (
				range * range  >= 
					(centerColor.r - compColor.r) * (centerColor.r - compColor.r) +
					(centerColor.g - compColor.g) * (centerColor.g - compColor.g) +
					(centerColor.b - compColor.b) * (centerColor.b - compColor.b)
			){
				// console.log(range*range);
				return true;
			} else {
				return false;
			}
		};

		function colorFilter(imgData, pixelNum, colorObj, range){
			// will return true or false based on wheter a the pixel color is within the specified range
			// an actual solution will involve color calculation in a color cube.   
			// console.log(colorObj);
			range = range || 100;

			// function colorRange(centerColor, compColor, range){...}
			if (
				colorRange(
					colorObj,
					{
						r : imgData.data[pixelNum],
						g : imgData.data[pixelNum+1],
						b : imgData.data[pixelNum+2]
					}, 
					range))
			{
				return true;
			} else {
				return false;
			}
		};

		function bloomSearch (startIndex, canvasWidth){
			//bloomSearch will search surrounding areas for further indication of desired image.
		};
		function vectorDetection (){};
		function mirrorDetection (){};

		function noiseReduce (imgData, pixelNum, canvasWidth, colorObj, radius, layers){
			radius = radius || 1;
			//Idea - check surrounding radius of pixels to determine if checked pixel is noise or valid object
			//one method is to average the surrounding 8 pixels
			//another method is to count the number of pixels in that 3x3 within the color range.
			//return a true if pixel is valid
			// radius (maximum search radius in pixels) and layers (spaced equalually radius/layers) inputs could lead to changing how 

			//get current x and y
			var count = 0;
			//filter down because I'm tired.
			for (var i = 0; i < radius; i++){
				if (colorFilter(imgData, pixelNum+i, colorObj)){
					count++;
				}
			}
			if (count>=Math.floor(radius*.75)){
				return true;
			} else {
				return false;
			}
			//get list of 8 indicies of pixels to check. Simple - do clockwise


			// check surrounding pixels - do not search within search radius of edge 
			//check vs method - 
		};

		function blobMeanLines (startX, startY, context, canvasWidth){
			//create 2 lines extending on x axis and y axis.  take the longest between the two and place a dot in the middle of the longest line. extend 
		};

		function pxTranslate (inputX, inputY, canvasWidth, picData){
			//function will take an x and y input for a position in canvas and respond with the pixel index starting at R.
			return inputY*canvasWidth+inputX-1;
		};

		function imgDataToQuad(imgData, canvasWidth){
			//function will take image data and make nested array quad with rgba values for each one of the quads.  [[R, G, B, A],[R, G, B, A],...] i.e. [[255,255,10,255],...]
			var result = [];
			for(i = 0; i < len; i += 4) {
				var quad = [];
			  quad[0].push(data[i]);
			  quad[1].push(data[i + 1]);
			  quad[2].push(data[i + 2]);
			  //quad[3].push(data[i + 3]);
			  result.push(quad);
			}
			return result;
		}

		function xyTranslate (inputIndex, canvasWidth, picData){
			//this function will take any one input from the data and return and object with x, y, r, g, b, a keys & appropriate values.  First values start at 0.
			result = {};

			// keep referneces to calc number so there aren't multiple calculations for the same stuff.
			var numAll = inputIndex / (canvasWidth * 4);
			var yCalc = Math.floor(numAll);
			var numX = ((numAll - yCalc) * (canvasWidth * 4 ));
			var xCalc = Math.floor( numX / 4 );
			
			//get y - divide by canvas.width to get row
			result.y = yCalc;
			//get x - divide by 4 to get which x pixel.  left of the decimal is which pixel.  
			result.x = xCalc;

			if (picData){
			// get start index the do the count up from there.
			var startInd = Math.floor( inputIndex / 4 ) * 4; 
				result.r = picData[startInd];
				result.g = picData[startInd + 1];
				result.b = picData[startInd + 2];
				result.a = picData[startInd + 3];
			}
			return result;
		}


// //From http://bl.ocks.org/mbostock/3886208

// var margin = {top: 20, right: 20, bottom: 30, left: 40},
//     width = 960 - margin.left - margin.right,
//     height = 500 - margin.top - margin.bottom;

// var x = d3.scale.ordinal()
//     .rangeRoundBands([0, width], .1);

// var y = d3.scale.linear()
//     .rangeRound([height, 0]);

// var color = d3.scale.ordinal()
//     .range(["#98abc5", "#8a89a6", "#7b6888", "#6b486b", "#a05d56", "#d0743c", "#ff8c00"]);

// var xAxis = d3.svg.axis()
//     .scale(x)
//     .orient("bottom");

// var yAxis = d3.svg.axis()
//     .scale(y)
//     .orient("left")
//     .tickFormat(d3.format(".2s"));

// var svg = d3.select("body").append("svg")
//     .attr("width", width + margin.left + margin.right)
//     .attr("height", height + margin.top + margin.bottom)
//   .append("g")
//     .attr("transform", "translate(" + margin.left + "," + margin.top + ")");

// d3.csv("data.csv", function(error, data) {
//   color.domain(d3.keys(data[0]).filter(function(key) { return key !== "State"; }));

//   data.forEach(function(d) {
//     var y0 = 0;
//     d.ages = color.domain().map(function(name) { return {name: name, y0: y0, y1: y0 += +d[name]}; });
//     d.total = d.ages[d.ages.length - 1].y1;
//   });

//   data.sort(function(a, b) { return b.total - a.total; });

//   x.domain(data.map(function(d) { return d.State; }));
//   y.domain([0, d3.max(data, function(d) { return d.total; })]);

//   svg.append("g")
//       .attr("class", "x axis")
//       .attr("transform", "translate(0," + height + ")")
//       .call(xAxis);

//   svg.append("g")
//       .attr("class", "y axis")
//       .call(yAxis)
//     .append("text")
//       .attr("transform", "rotate(-90)")
//       .attr("y", 6)
//       .attr("dy", ".71em")
//       .style("text-anchor", "end")
//       .text("Population");

//   var state = svg.selectAll(".state")
//       .data(data)
//     .enter().append("g")
//       .attr("class", "g")
//       .attr("transform", function(d) { return "translate(" + x(d.State) + ",0)"; });

//   state.selectAll("rect")
//       .data(function(d) { return d.ages; })
//     .enter().append("rect")
//       .attr("width", x.rangeBand())
//       .attr("y", function(d) { return y(d.y1); })
//       .attr("height", function(d) { return y(d.y0) - y(d.y1); })
//       .style("fill", function(d) { return color(d.name); });

//   var legend = svg.selectAll(".legend")
//       .data(color.domain().slice().reverse())
//     .enter().append("g")
//       .attr("class", "legend")
//       .attr("transform", function(d, i) { return "translate(0," + i * 20 + ")"; });

//   legend.append("rect")
//       .attr("x", width - 18)
//       .attr("width", 18)
//       .attr("height", 18)
//       .style("fill", color);

//   legend.append("text")
//       .attr("x", width - 24)
//       .attr("y", 9)
//       .attr("dy", ".35em")
//       .style("text-anchor", "end")
//       .text(function(d) { return d; });

// });
// //End from http://bl.ocks.org/mbostock/3886208

	</script>
</html>