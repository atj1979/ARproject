<!DOCTYPE html>
<html>
	<head>

	<link rel="stylesheet" type="text/css" href="stylesheets/style.css">
	</head>
	<body>
		<h1>AR Project</h1>
		<h4>Construction Zone!!!!!!</h4>

		<!--  Code taken from http://davidwalsh.name/browser-camera
		Ideally these elements aren't created until it's confirmed that the 
		client supports video/camera, but for the sake of illustrating the 
		elements involved, they are created with markup (not JavaScript)
		-->
		<video id="video" width="640" height="480" autoplay></video>
		<button id="snap">Snap Photo</button>
		<canvas id="canvas" width="640" height="480" style="border:1px solid #000000;"></canvas>



	</body>
	<script>



	/* Image process idea.  
		per image - define minimum size ( 100x100 in field of 1000x1000) <- performance idea
		per image if pixel color matches designated color within a range, 
			begin searching surrounding pixels, 
				Stage 1 : only store left most, right most, top most, bottom most 
					This gets a box to work with
				Stage 2 : identify local minimums and maximums within range of +/- a few pixels 
					This should get us points to draw a line and identify an aspect for image rendering and aid in shape recognition
	*/






		// Code taken from http://davidwalsh.name/browser-camera
		// Put event listeners into place
		window.addEventListener("DOMContentLoaded", function() {
			// Grab elements, create settings, etc.
			canvas = document.getElementById("canvas");
			context = canvas.getContext("2d");
			video = document.getElementById("video");

			// My code - overlay the canvas on top of the video.
			canvas.setAttribute("style", "left:" + video.offsetLeft + "px");
			canvas.setAttribute("style", "top:" + - video.offsetTop + "px");

			//videoObj are the constraints of the video stream
			videoObj = { "video": true , "audio" :false};
			errBack = function(error) {
				console.log("Video capture error: ", error.code); 
			};
			var ONCE = false;
			// Put video listeners into place
			if(navigator.getUserMedia) { // Standard
				navigator.getUserMedia(videoObj, function(stream) {
					if (!ONCE){
						console.log("got to STAGE 1 - vanilla flavor");
						console.log(stream);
						ONCE=true;
					}
					video.src = stream;
					video.play();
				}, errBack);
			} else if(navigator.webkitGetUserMedia) { 
				// WebKit-prefixed
				console.log("got to STAGE 2 - WebKit-prefixed");
				navigator.webkitGetUserMedia(videoObj, function(stream){
					video.src = window.webkitURL.createObjectURL(stream);
					video.play();
				}, errBack);
			}
			else if(navigator.mozGetUserMedia) { 
				// Firefox-prefixed
				console.log("got to STAGE 3 - Firefox-prefixed");
				navigator.mozGetUserMedia(videoObj, function(stream){
					video.src = window.URL.createObjectURL(stream);
					video.play();
				}, errBack);
			}
		}, false);

		// Located from MDN WebRTC_API Taking Still Photos
		function takePicture() {
	    var context = canvas.getContext('2d');
	   
	      context.drawImage(video, 0, 0);


	      //get the image data using canvas.getContext('2d').getImageData(starting x, starting y, width from x, height from y);
	      // the resultant data is a one dimensional array, every 4 elements are on pixel with the RGBA order ranged 0-255 (red green blue opacity)
	    	var data = context.getImageData(0,0, canvas.width, canvas.height);
	    	console.dir(data);


	    	//clear the canvas after we have our data
	    	context.clearRect ( 0 , 0 , canvas.width, canvas.height );
	    
	    console.log("takePicture worked!!!!")
	  }
		document.getElementById("snap").addEventListener('click', function (){takePicture()
		});

		function processImage (searchSignature, overlay){
			// searchSignature is an object containing minWidth, minHeight, maxHeight, maxWidth, minRed, maxRed, minBlue, maxBlue, minGreen, maxGreen - all opacity will be assumed @255, so no setting provided
			//optional --> lines equations to identify points/ratios of object proportions

			//overlay will be an object containing whatever we want to overlay with meta-data for desired size based on % of found object 

			// if machine learning can be found to be reasonable with time (local calculation likely)

			//search idea, break picture into grid. Search 1/10000px or 1/2500 px for appropriate color, then surrounding px color to get shape.  store leftmost, right most, topmost ,bottomost to get box.  also store local height max +/- a few pixels.  also store local minimums +/- pixels.  attempt to plot a line to identify a general shape and compare top/bottom ratios with provided ratios.   start with 640x480 and see how that goes. 
			//another idea with M Macatano, create color count for blocks of  
		}
		function xyTranslate (inputIndex){
			//this function will take any one input from the data and return and object with x, y, r, g, b, a keys & appropriate values.
			result = {};
			//get y - divide by canvas.width to get row
			result.y = Math.floor(inputIndex/canvas.width);
			//get x - divide by 4 to get which x pixel.  left of the decimal is which pixel.  

			//right of the decimal is which RGB or A , R=.00, G=.25, B=.5, A=.75








			return result;
		}


	</script>
</html>