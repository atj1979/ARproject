<!DOCTYPE html>
<html>
	<head>

	<link rel="stylesheet" type="text/css" href="stylesheets/style.css">
	</head>
	<body>
		<h1>AR Project</h1>
		<h4>Construction Zone!!!!!!</h4>

		<!--  Code taken from http://davidwalsh.name/browser-camera
		Ideally these elements aren't created until it's confirmed that the 
		client supports video/camera, but for the sake of illustrating the 
		elements involved, they are created with markup (not JavaScript)
		-->
		<video id="video" width="640" height="480" autoplay></video>
		<button id="snap">Snap Photo</button>
		<canvas id="canvas" width="640" height="480" style="border:1px solid #000000;"></canvas>
		<div style="display:none;">
		  <img id="source" src="./images/shriner.jpeg" width="300" height="227" />
		</div>


	</body>
	<script>



	/* Image process idea.  
		per image - define minimum size ( 100x100 in field of 1000x1000) <- performance idea
		per image if pixel color matches designated color within a range, 
			begin searching surrounding pixels, 
				Stage 1 : only store left most, right most, top most, bottom most 
					This gets a box to work with
				Stage 2 : identify local minimums and maximums within range of +/- a few pixels 
					This should get us points to draw a line and identify an aspect for image rendering and aid in shape recognition
	*/






		// Code taken from http://davidwalsh.name/browser-camera
		// Put event listeners into place
		window.addEventListener("DOMContentLoaded", function() {
			// Grab elements, create settings, etc.
			var canvas = document.getElementById("canvas");
			var context = canvas.getContext("2d");
			var video = document.getElementById("video");

			// My code - overlay the canvas on top of the video.
			// canvas.setAttribute("style", "left:" + video.offsetLeft + "px");
			// canvas.setAttribute("style", "top:" + - video.offsetTop + "px");

			//videoObj are the constraints of the video stream
			var videoObj = { "video": true , "audio" :false};
			var errBack = function (error) {
				console.log("Video capture error: ", error.code); 
			};
			var ONCE = false;
			// Put video listeners into place
			if(navigator.getUserMedia) { // Standard
				navigator.getUserMedia(videoObj, function(stream) {
					if (!ONCE){
						console.log("got to STAGE 1 - vanilla flavor");
						console.log(stream);
						ONCE=true;
					}
					video.src = stream;
					video.play();
				}, errBack);
			} else if(navigator.webkitGetUserMedia) { 
				// WebKit-prefixed
				console.log("got to STAGE 2 - WebKit-prefixed");
				navigator.webkitGetUserMedia(videoObj, function(stream){
					video.src = window.webkitURL.createObjectURL(stream);
					video.play();
				}, errBack);
			}
			else if(navigator.mozGetUserMedia) { 
				// Firefox-prefixed
				console.log("got to STAGE 3 - Firefox-prefixed");
				navigator.mozGetUserMedia(videoObj, function(stream){
					video.src = window.URL.createObjectURL(stream);
					video.play();
				}, errBack);
			}
		}, false);

		// Located from MDN WebRTC_API Taking Still Photos
		function takePicture () {
	    var context = canvas.getContext('2d');
	   	var img = document.getElementById('source');
	      //I think we have to draw the image in order to get the data from it.
	      context.drawImage(video, 0, 0);

	      //get the image data using canvas.getContext('2d').getImageData(starting x, starting y, width from x, height from y);
	      // the resultant data is a one dimensional array, every 4 elements are on pixel with the RGBA order ranged 0-255 (red green blue opacity)
	    	var data = context.getImageData(0,0, canvas.width, canvas.height);

	    	//clear the canvas after we have our data
	    	context.clearRect ( 0 , 0 , canvas.width, canvas.height );
	    	processImage(context, data, null, canvas.width, img);
	    // console.log("takePicture worked!!!!")
	  }

		document.getElementById("snap").addEventListener('click', function (){
			takePicture();
			setInterval(takePicture, 30);
		});

		function processImage (context, imgData, searchSignature, canvasWidth, overlay){
			var start = new Date;
			// searchSignature is an object containing minWidth, minHeight, maxHeight, maxWidth, minRed, maxRed, minBlue, maxBlue, minGreen, maxGreen - all opacity will be assumed @255, so no setting provided
			//optional --> lines equations to identify points/ratios of object proportions


			//overlay will be an object containing whatever we want to overlay with meta-data for desired size based on % of found object 

			// if machine learning can be found to be reasonable with time (local calculation likely)

			//search idea, break picture into grid. Search 1/10000px or 1/2500 px for appropriate color, then surrounding px color to get shape.  store leftmost, right most, topmost ,bottomost to get box.  also store local height max +/- a few pixels.  also store local minimums +/- pixels.  attempt to plot a line to identify a general shape and compare top/bottom ratios with provided ratios.   start with 640x480 and see how that goes. 
			//another idea with M Macatano, create color count for blocks of size 100x100 or so.
			//Basic Search - search every pixel.
			//make new array to store results
			var resolution = 8;
			var pos;
			var average = {
				x:0,
				y:0,
				counter:0
			};

			//guessed mcdonalds colors >150, >150, <120 RGB
			// better color identification could be identified by 3 phase - vector analysis
			//context.fillStyle = "yellow";
			
			for (var i = 0; i < imgData.data.length; i+=resolution){
				if (
					colorFilter(imgData, i) &&
					noiseReduce(imgData, i, canvasWidth);
				){
					pos = xyTranslate(i, canvasWidth);
					average.counter+=1;
					average.x+=pos.x;
					average.y+=pos.y;
					context.fillRect(pos.x, pos.y, 3, 2);
				}
			}
			average.x=average.x/average.counter;
			average.y=average.y/average.counter;
			// console.log(average);
			//context.fillStyle = "black";
			context.drawImage(overlay,average.x, average.y, 423, 119);
			//context.fillRect(average.x, average.y, resolution, resolution);


			var stop = new Date;
			// console.log("Calc time each frame",stop-start);
		};

		function colorCount (colorObj){
			//will get a count of pixels within a color range.
			//colorObj will contain min and max values for each RGB. 
		};

		function colorFilter(imgData, pixelNum, colorObj){
			// will return true or false based on wheter a the pixel color is within the specified range
			if (
				imgData.data[pixelNum]>150 && 
				imgData.data[pixelNum+1]>150 && 
				// imgData.data[i+1]<220 &&
				imgData.data[pixelNum+2]<110
				)
			{
				return true;
			} else {
				return false;
			}

		};
		function bloomSearch (startIndex, canvasWidth){
			//bloomSearch will search surrounding areas for further indication of desired image.

		};
		function vectorDetection (){};
		function mirrorDetection (){};
		function noiseReduce (imgData, pixelNum, canvasWidth, radius, layers){
			radius = radius || 1;
			//Idea - check surrounding radius of pixels to determine if checked pixel is noise or valid object
			//one method is to average the surrounding 8 pixels
			//another method is to count the number of pixels in that 3x3 within the color range.
			//return a true if pixel is valid
			// radius (maximum search radius in pixels) and layers (spaced equalually radius/layers) inputs could lead to changing how 

			//get current x and y
			var pixel = xyTranslate(pixelNum, canvasWidth);
			var count = 0;
			//filter down because I'm tired.
			for (var i = 0; i < 4; i++){
				if (colorFilter(imgData, pixelNum+i*canvasWidth)){
					count++;
				}
			}
			if (count>=3){
				return true;
			} else {
				return false;
			}
			//get list of 8 indicies of pixels to check. Simple - do clockwise


			// check surrounding pixels - do not search within search radius of edge 
			//check vs method - 


		};
		function blobMeanLines (startX, startY, context, canvasWidth){

			//create 2 lines extending on x axis and y axis.  take the longest between the two and place a dot in the middle of the longest line. extend 

		};

		function pxTranslate (inputX, inputY, canvasWidth, picData){
			//function will take an x and y input for a position in canvas and respond with the pixel index starting at R.
			return inputY*canvasWidth+inputX-1;
		};

		function xyTranslate (inputIndex, canvasWidth, picData){
			//this function will take any one input from the data and return and object with x, y, r, g, b, a keys & appropriate values.  First values start at 0.
			result = {};

			// keep referneces to calc number so there aren't multiple calculations for the same stuff.
			var numAll = inputIndex / (canvasWidth * 4);
			var yCalc = Math.floor(numAll);
			var numX = ((numAll - yCalc) * (canvasWidth * 4 ));
			var xCalc = Math.floor( numX / 4 );
			
			//get y - divide by canvas.width to get row
			result.y = yCalc;
			//get x - divide by 4 to get which x pixel.  left of the decimal is which pixel.  
			result.x = xCalc;

			if (picData){
			// get start index the do the count up from there.
			var startInd = Math.floor( inputIndex / 4 ) * 4; 
				result.r = picData[startInd];
				result.g = picData[startInd + 1];
				result.b = picData[startInd + 2];
				result.a = picData[startInd + 3];
			}
			return result;
		}


	</script>
</html>